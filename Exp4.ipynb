{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from scipy.special import softmax \n",
        "import torch.backends.cudnn as cudnn\n",
        "import random\n",
        "import pickle\n",
        "import itertools"
      ],
      "metadata": {
        "id": "mDWM3Mc-z1cW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "checkpoints = '/content/drive/My Drive/Colab Notebooks/cse559a/'\n",
        "if not os.path.exists(checkpoints):\n",
        "  os.makedirs(checkpoints)\n",
        "  \n",
        "if not os.path.exists('imagenet_val'):\n",
        "  if not os.path.exists(checkpoints + 'imagenet_val.tar'):\n",
        "    print(\"Downloading archive...\")\n",
        "    os.chdir(checkpoints)\n",
        "    !wget -nv -O imagenet_val.tar -L https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
        "    os.chdir('/content/')\n",
        "  print(\"Copying to local runtime...\")\n",
        "  shutil.copy(checkpoints + 'imagenet_val.tar', './imagenet_val.tar')\n",
        "  print(\"Uncompressing...\")\n",
        "  !mkdir imagenet_val\n",
        "  !tar -xf imagenet_val.tar -C ./imagenet_val/\n",
        "  !rm imagenet_val.tar\n",
        "  os.chdir('./imagenet_val') \n",
        "  !wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash\n",
        "  os.chdir('/content/')\n",
        "print(\"Data ready!\")\n",
        "\n",
        "if not os.path.exists('exp_v0.py'):\n",
        "  shutil.copy(checkpoints + 'exp_v0.py', './exp_v0.py')\n",
        "  print(\"File imported\")\n",
        "from exp_v0 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRpsOuF6z2Bw",
        "outputId": "fdc2ed28-355e-48aa-e9e7-9a30d9ec6ff3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _fix_randomness(seed=0):\n",
        "    ### Fix randomness \n",
        "    np.random.seed(seed=seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "# Returns a dataframe with:\n",
        "# 1) Set sizes for all test-time examples.\n",
        "# 2) topk for each example, where topk means which score was correct.\n",
        "def sizes_topk(modelname, datasetname, datasetpath, alpha, kreg, lamda, randomized, n_data_conf, n_data_val, bsz, predictor):\n",
        "    _fix_randomness()\n",
        "    ### Experiment logic\n",
        "    naive_bool = predictor == 'Naive'\n",
        "    lamda_predictor = lamda\n",
        "    if predictor in ['Naive', 'APS']:\n",
        "        lamda_predictor = 0 # No regularization.\n",
        "\n",
        "    ### Data Loading\n",
        "    logits = get_logits_dataset(modelname, datasetname, datasetpath)\n",
        "    logits_cal, logits_val = split2(logits, n_data_conf, n_data_val) # A new random split for every trial\n",
        "    # Prepare the loaders\n",
        "    loader_cal = torch.utils.data.DataLoader(logits_cal, batch_size = bsz, shuffle=False, pin_memory=True)\n",
        "    loader_val = torch.utils.data.DataLoader(logits_val, batch_size = bsz, shuffle=False, pin_memory=True)\n",
        "\n",
        "    ### Instantiate and wrap model\n",
        "    model = create_model(modelname)\n",
        "    # Conformalize the model\n",
        "    conformal_model = ConformalModelLogits(model, loader_cal, alpha=alpha, kreg=kreg, lamda=lamda_predictor, randomized=randomized, naive=naive_bool)\n",
        "\n",
        "    df = pd.DataFrame(columns=['model','predictor','size','topk','lamda'])\n",
        "    corrects = 0\n",
        "    denom = 0\n",
        "    ### Perform experiment\n",
        "    for i, (logit, target) in tqdm(enumerate(loader_val)):\n",
        "        # compute output\n",
        "        output, S = conformal_model(logit) # This is a 'dummy model' which takes logits, for efficiency.\n",
        "        # measure accuracy and record loss\n",
        "        size = np.array([x.size for x in S])\n",
        "        I, _, _ = sort_sum(logit.numpy()) \n",
        "        topk = np.where((I - target.view(-1,1).numpy())==0)[1]+1 \n",
        "        batch_df = pd.DataFrame({'model': modelname, 'predictor': predictor, 'size': size, 'topk': topk, 'lamda': lamda})\n",
        "        df = pd.concat([df, batch_df], ignore_index=True)\n",
        "\n",
        "        corrects += sum(topk <= size)\n",
        "        denom += output.shape[0] \n",
        "\n",
        "    print(f\"Empirical coverage: {corrects/denom} with lambda: {lamda}\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "pnek3fpDu3Ug"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting code\n",
        "def adaptiveness_table(df_big):\n",
        "\n",
        "    sizes = [[0,1],[2,3],[4,6],[7,10],[11,100],[101,1000]]\n",
        "\n",
        "    tbl = \"\"\n",
        "    tbl += \"\\\\begin{table}[t]\\n\"\n",
        "    tbl += \"\\\\centering\\n\"\n",
        "    tbl += \"\\\\small\\n\"\n",
        "    tbl += \"\\\\begin{tabular}{l\"\n",
        "\n",
        "    lamdaunique = df_big.lamda.unique()\n",
        "\n",
        "    multicol_line = \"        \" \n",
        "    midrule_line = \"        \"\n",
        "    label_line = \"size \"\n",
        "\n",
        "    for i in range(len(lamdaunique)):\n",
        "        j = 2*i \n",
        "        tbl += \"cc\"\n",
        "        multicol_line += (\" & \\multicolumn{2}{c}{$\\lambda={\" + str(lamdaunique[i]) + \"}$}    \")\n",
        "        midrule_line += (\" \\cmidrule(r){\" + str(j+1+1) + \"-\" + str(j+2+1) + \"}    \")\n",
        "        label_line += \"&cnt & cvg     \"\n",
        "\n",
        "    tbl += \"} \\n\"\n",
        "    tbl += \"\\\\toprule\\n\"\n",
        "    multicol_line += \"\\\\\\\\ \\n\"\n",
        "    midrule_line += \"\\n\"\n",
        "    label_line += \"\\\\\\\\ \\n\"\n",
        "    \n",
        "    tbl = tbl + multicol_line + midrule_line + label_line\n",
        "    tbl += \"\\\\midrule \\n\"\n",
        "\n",
        "    #DEBUG\n",
        "    total_coverages = {lamda:0 for lamda in lamdaunique}\n",
        "    for sz in sizes:\n",
        "        if sz[0] == sz[1]:\n",
        "            tbl += str(sz[0]) + \"     \"\n",
        "        else:\n",
        "            tbl += str(sz[0]) + \" to \" + str(sz[1]) + \"     \"\n",
        "        df = df_big[(df_big['size'] >= sz[0]) & (df_big['size'] <= sz[1])]\n",
        "\n",
        "        for lamda in lamdaunique:\n",
        "            df_small = df[df.lamda == lamda]\n",
        "            if(len(df_small)==0):\n",
        "                tbl += f\" & 0 & \"\n",
        "                continue\n",
        "            cvg = len(df_small[df_small.topk <= df_small['size']])/len(df_small)\n",
        "            #diff = df_small['topk'].mean()\n",
        "            total_coverages[lamda] += cvg * len(df_small)/len(df_big)*len(lamdaunique)\n",
        "            tbl +=  f\" & {len(df_small)} & {cvg:.2f} \"\n",
        "            #tbl +=  f\" & {len(df_small)} & {cvg:.2f} & {diff:.1f}  \"\n",
        "\n",
        "        tbl += \"\\\\\\\\ \\n\"\n",
        "    tbl += \"\\\\bottomrule\\n\"\n",
        "    tbl += \"\\\\end{tabular}\\n\"\n",
        "    tbl += \"\\\\caption{\\\\textbf{Coverage conditional on set size.} We report average coverage of images stratified by the size of the set output by a conformalized ResNet-152 for $k_{reg}=5$ and varying $\\lambda$.}\\n\"\n",
        "    tbl += \"\\\\label{table:adaptiveness}\\n\"\n",
        "    tbl += \"\\\\end{table}\\n\"\n",
        "\n",
        "    print(total_coverages)\n",
        "\n",
        "    return tbl\n"
      ],
      "metadata": {
        "id": "VxcgXtUn0eMZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelnames = ['ResNet152']\n",
        "alphas = [0.1]\n",
        "predictors = ['RAPS']\n",
        "lamdas = [0, 0.001, 0.01, 0.1, 1] \n",
        "params = list(itertools.product(modelnames, alphas, predictors, lamdas))\n",
        "m = len(params)\n",
        "datasetname = 'ImagenetVal'\n",
        "datasetpath = './imagenet_val/'\n",
        "kreg = 5 \n",
        "randomized = True\n",
        "n_data_conf = 20000\n",
        "n_data_val = 20000\n",
        "bsz = 64\n",
        "cudnn.benchmark = True\n",
        "\n",
        "### Perform the experiment\n",
        "df = pd.DataFrame(columns = [\"model\",\"predictor\",\"size\",\"topk\",\"lamda\"])\n",
        "for i in range(m):\n",
        "    modelname, alpha, predictor, lamda = params[i]\n",
        "    print(f'Model: {modelname} | Desired coverage: {1-alpha} | Predictor: {predictor} | Lambda = {lamda}')\n",
        "    out = sizes_topk(modelname, datasetname, datasetpath, alpha, kreg, lamda, randomized, n_data_conf, n_data_val, bsz, predictor)\n",
        "    df = pd.concat([df, out], ignore_index=True) \n",
        "\n",
        "\n",
        "tbl = adaptiveness_table(df)\n",
        "print(tbl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_R-7NEgvBcb",
        "outputId": "63e1bccc-d3e9-4ff9-f627-4baa12b17929"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: ResNet152 | Desired coverage: 0.9 | Predictor: RAPS | Lambda = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:00<00:00, 317MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing logits for model (only happens once).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [08:27<00:00,  3.08it/s]\n",
            "313it [00:05, 56.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical coverage: 0.9018 with lambda: 0\n",
            "Model: ResNet152 | Desired coverage: 0.9 | Predictor: RAPS | Lambda = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "313it [00:05, 57.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical coverage: 0.8984 with lambda: 0.001\n",
            "Model: ResNet152 | Desired coverage: 0.9 | Predictor: RAPS | Lambda = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "313it [00:05, 57.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical coverage: 0.8978 with lambda: 0.01\n",
            "Model: ResNet152 | Desired coverage: 0.9 | Predictor: RAPS | Lambda = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "313it [00:05, 57.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical coverage: 0.8991 with lambda: 0.1\n",
            "Model: ResNet152 | Desired coverage: 0.9 | Predictor: RAPS | Lambda = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "313it [00:05, 57.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empirical coverage: 0.8995 with lambda: 1\n",
            "{0: 0.9018, 0.001: 0.8983999999999999, 0.01: 0.8977999999999999, 0.1: 0.8991, 1: 0.8995000000000001}\n",
            "\\begin{table}[t]\n",
            "\\centering\n",
            "\\small\n",
            "\\begin{tabular}{lcccccccccc} \n",
            "\\toprule\n",
            "         & \\multicolumn{2}{c}{$\\lambda={0}$}     & \\multicolumn{2}{c}{$\\lambda={0.001}$}     & \\multicolumn{2}{c}{$\\lambda={0.01}$}     & \\multicolumn{2}{c}{$\\lambda={0.1}$}     & \\multicolumn{2}{c}{$\\lambda={1}$}    \\\\ \n",
            "         \\cmidrule(r){2-3}     \\cmidrule(r){4-5}     \\cmidrule(r){6-7}     \\cmidrule(r){8-9}     \\cmidrule(r){10-11}    \n",
            "size &cnt & cvg     &cnt & cvg     &cnt & cvg     &cnt & cvg     &cnt & cvg     \\\\ \n",
            "\\midrule \n",
            "0 to 1      & 11638 & 0.88  & 11543 & 0.88  & 11230 & 0.89  & 10476 & 0.92  & 10024 & 0.93 \\\\ \n",
            "2 to 3      & 3725 & 0.92  & 3698 & 0.91  & 3740 & 0.92  & 3847 & 0.93  & 3925 & 0.94 \\\\ \n",
            "4 to 6      & 1215 & 0.90  & 1289 & 0.91  & 1705 & 0.92  & 4220 & 0.89  & 6051 & 0.83 \\\\ \n",
            "7 to 10      & 694 & 0.94  & 768 & 0.92  & 1311 & 0.91  & 1435 & 0.71  & 0 & \\\\ \n",
            "11 to 100      & 2178 & 0.95  & 2602 & 0.93  & 2014 & 0.86  & 22 & 0.59  & 0 & \\\\ \n",
            "101 to 1000      & 550 & 0.98  & 100 & 0.90  & 0 &  & 0 &  & 0 & \\\\ \n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\\caption{\\textbf{Coverage conditional on set size.} We report average coverage of images stratified by the size of the set output by a conformalized ResNet-152 for $k_{reg}=5$ and varying $\\lambda$.}\n",
            "\\label{table:adaptiveness}\n",
            "\\end{table}\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}